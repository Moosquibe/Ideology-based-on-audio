{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw Audio classification with WaveNet\n",
    "Requires Pytorch 0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import network_modules as wn\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "WORKDIR = \"/data/WorkData/ideology_from_audio/RESULTS/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vstack_with_padding(a,b):\n",
    "    \"\"\"\n",
    "    Stacks one dimensional arrays on top of each other.\n",
    "    \"\"\"\n",
    "    if len(a.shape) == 1:\n",
    "        a = a.reshape(1,-1)\n",
    "    if len(b.shape) == 1:\n",
    "        b = b.reshape(1,-1)\n",
    "        \n",
    "    if a.shape[1] > b.shape[1]:\n",
    "        b = np.hstack((b, np.zeros((b.shape[0],a.shape[1]-b.shape[1]))))\n",
    "    elif b.shape[1] > a.shape[1]:\n",
    "        a = np.hstack((a, np.zeros((a.shape[0],b.shape[1]-a.shape[1]))))\n",
    "    return np.vstack((a,b))\n",
    "\n",
    "def get_minibatch(data_df, batch_size = 32, seed = 0):\n",
    "    \"\"\" \n",
    "    Returns a minibatch of size batch_size from data_dict,\n",
    "    starting at index given by seed.\n",
    "    \"\"\"\n",
    "    N = len(data_df.index)\n",
    "    assert seed < N, \"seed out of bounds\"\n",
    "    X_batch = None\n",
    "    y_batch = []\n",
    "    for i in range(seed, min(seed + batch_size, N)):\n",
    "        row = data_df.iloc[i]\n",
    "        used_word = row.Word\n",
    "        filename = row.Filename\n",
    "        path = WORKDIR + 'WordAudio/' + used_word + \"/\" + filename\n",
    "        waveform, _ = librosa.load(path)\n",
    "        if X_batch is None:\n",
    "            X_batch = waveform\n",
    "        else:\n",
    "            X_batch = vstack_with_padding(X_batch, waveform)\n",
    "        y_batch.append(row.Ideology)\n",
    "    return X_batch, np.array(y_batch)\n",
    "\n",
    "def get_accuracy(data_df, classifier, threshold = 0.5, \n",
    "                 verbose = True, gpu = False):\n",
    "    \"\"\"\n",
    "    Computes accuracy of classifier over examples in data_df\n",
    "    \"\"\"\n",
    "    if gpu and torch.cuda.is_available():\n",
    "        classifier = classifier.cuda()\n",
    "    \n",
    "    classifier.test()\n",
    "    \n",
    "    correct = 0\n",
    "    N = len(data_df.index)\n",
    "    for i in range(N):\n",
    "        if verbose and i % 10 == 0:\n",
    "            print(\" {}/{}\".format(i,N))\n",
    "        row = data_df.iloc[i]\n",
    "        used_word = row.Word\n",
    "        filename = row.Filename\n",
    "        path = WORKDIR + 'WordAudio/' + used_word + \"/\" + filename\n",
    "        waveform, sample_rate = librosa.load(path)\n",
    "        inp = torch.Tensor(waveform).view(1,1,-1)\n",
    "        if gpu and torch.cuda.is_available():\n",
    "            inp = inp.cuda()\n",
    "        scores = classifier(inp)[0]\n",
    "        if scores[0] >= threshold:\n",
    "            y_pred = 1\n",
    "        else:\n",
    "            y_pred = 0\n",
    "        y_gt = row.Ideology\n",
    "        if y_pred == y_gt:\n",
    "            correct += 1\n",
    "    classifier = None\n",
    "    torch.cuda.empty_cache()\n",
    "            \n",
    "    return float(correct) / N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading the data and defining test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Word</th>\n",
       "      <th>Year</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Ideology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roberts</td>\n",
       "      <td>FEDERAL</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008_FEDERAL6502.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>goldstein</td>\n",
       "      <td>JUSTICE</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012_JUSTICE15772.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ginsburg</td>\n",
       "      <td>ISSUE</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008_ISSUE3553.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>olson</td>\n",
       "      <td>GOVERNMENT</td>\n",
       "      <td>2007</td>\n",
       "      <td>2007_GOVERNMENT3580.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>breyer</td>\n",
       "      <td>ARGUMENT</td>\n",
       "      <td>2011</td>\n",
       "      <td>2011_ARGUMENT6159.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Speaker        Word  Year                 Filename  Ideology\n",
       "0    roberts     FEDERAL  2008     2008_FEDERAL6502.wav         1\n",
       "1  goldstein     JUSTICE  2012    2012_JUSTICE15772.wav         0\n",
       "2   ginsburg       ISSUE  2008       2008_ISSUE3553.wav         0\n",
       "3      olson  GOVERNMENT  2007  2007_GOVERNMENT3580.wav         1\n",
       "4     breyer    ARGUMENT  2011    2011_ARGUMENT6159.wav         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = pd.read_csv(WORKDIR + \"final_raw_wave_ideology.csv\").drop('Unnamed: 0', axis = 1)\n",
    "records.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_words = list(map(lambda s: s.upper(), ['Justice', 'Honor', 'Federal', 'Congress', \n",
    "              'Government', 'Evidence', 'Argument', 'Issue', 'Science', 'Taxation']))\n",
    "records_by_word = {}\n",
    "\n",
    "for used_word in used_words:\n",
    "    records_by_word[used_word] = records[records.Word == used_word]\n",
    "    records_by_word[used_word] = records_by_word[used_word].reset_index().drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not training on SCIENCE and TAXATION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JUSTICE',\n",
       " 'HONOR',\n",
       " 'FEDERAL',\n",
       " 'CONGRESS',\n",
       " 'GOVERNMENT',\n",
       " 'EVIDENCE',\n",
       " 'ARGUMENT',\n",
       " 'ISSUE']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_used_words = used_words[:-2]\n",
    "train_used_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do a word by word splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ratio = 0.1\n",
    "\n",
    "records_by_word_train = {}\n",
    "records_by_word_test = {}\n",
    "\n",
    "for used_word in used_words:\n",
    "    recs = records_by_word[used_word]\n",
    "    if used_word in train_used_words:\n",
    "        num_occur = len(recs.index)\n",
    "        split_index = int(num_occur * (1-valid_ratio))\n",
    "        records_by_word_train[used_word] = recs.iloc[:split_index].reset_index().drop('index', axis = 1)\n",
    "        records_by_word_test[used_word] = recs.iloc[split_index:].reset_index().drop('index', axis = 1)\n",
    "        \n",
    "    else:\n",
    "        records_by_word_test[used_word] = recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also get a global training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Speaker</th>\n",
       "      <th>Word</th>\n",
       "      <th>Year</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Ideology</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>waxman</td>\n",
       "      <td>FEDERAL</td>\n",
       "      <td>2004</td>\n",
       "      <td>2004_FEDERAL3311.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>waxman</td>\n",
       "      <td>CONGRESS</td>\n",
       "      <td>2010</td>\n",
       "      <td>2010_CONGRESS7720.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>long</td>\n",
       "      <td>JUSTICE</td>\n",
       "      <td>2009</td>\n",
       "      <td>2009_JUSTICE10047.wav</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kennedy</td>\n",
       "      <td>ARGUMENT</td>\n",
       "      <td>2012</td>\n",
       "      <td>2012_ARGUMENT6968.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>katsas</td>\n",
       "      <td>JUSTICE</td>\n",
       "      <td>2008</td>\n",
       "      <td>2008_JUSTICE8547.wav</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Speaker      Word  Year               Filename  Ideology\n",
       "0   waxman   FEDERAL  2004   2004_FEDERAL3311.wav         0\n",
       "1   waxman  CONGRESS  2010  2010_CONGRESS7720.wav         0\n",
       "2     long   JUSTICE  2009  2009_JUSTICE10047.wav         0\n",
       "3  kennedy  ARGUMENT  2012  2012_ARGUMENT6968.wav         1\n",
       "4   katsas   JUSTICE  2008   2008_JUSTICE8547.wav         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records_train = pd.concat(records_by_word_train.values())\n",
    "records_train = records.iloc[np.random.permutation(len(records_train))]\n",
    "records_train = records_train.reset_index().drop('index', axis = 1)\n",
    "records_test = pd.concat(records_by_word_test.values())\n",
    "records_test = records_test.reset_index().drop('index', axis = 1)\n",
    "records_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training a custom classifier over the full training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = wn.WaveNet(\n",
    "                layer_size = 8,\n",
    "                stack_size = 2,\n",
    "                in_channels = 1,\n",
    "                res_channels = 4,\n",
    "                skip_channels = 16,\n",
    "                pooling_kernel = 2,\n",
    "                classes = 2\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainWaveNet(classifier, data, valid_data, num_epochs = 10, \n",
    "          batch_size = 32, verbose = False, gpu = False):\n",
    "    ##########################################\n",
    "    ############### INITIALIZING #############\n",
    "    ##########################################\n",
    "    N = len(data.index)\n",
    "    batches_per_epoch = int(N / batch_size) + 1\n",
    "    \n",
    "    print(\" Computing initial accuracy on validation set...\")\n",
    "    acc = get_accuracy(valid_data, classifier, verbose = False)\n",
    "    print(\" Initial accuracy: {}\".format(acc))\n",
    "\n",
    "    if gpu and torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        classifier = classifier.cuda()\n",
    "    else:\n",
    "        classifier = classifier.cpu()\n",
    "        \n",
    "    optimizer = torch.optim.Adam(\n",
    "                            classifier.parameters(),\n",
    "                            lr = 0.1,\n",
    "                            betas = (0.9, 0.999),\n",
    "                            eps = 1e-08,\n",
    "                            weight_decay = 0.01)\n",
    "    \n",
    "    ##########################################\n",
    "    ########### TRAINING ITERATION ###########\n",
    "    ##########################################\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        classifier.train()\n",
    "        print(\"Epoch: {}/{}\".format(epoch + 1, num_epochs))\n",
    "        seed = 0\n",
    "        for batch in range(batches_per_epoch):\n",
    "            \n",
    "            ##############################\n",
    "            ##### PREPARE DATA BATCH #####\n",
    "            ##############################\n",
    "            X_batch, y_batch = get_minibatch(data, \n",
    "                                             batch_size = batch_size, \n",
    "                                             seed = seed)\n",
    "            current_batch_size = X_batch.shape[0]\n",
    "            \n",
    "\n",
    "            X_batch = torch.tensor(X_batch, requires_grad = False, \n",
    "                                   dtype = torch.float)\n",
    "            y_batch = torch.tensor(y_batch, requires_grad = False, \n",
    "                                   dtype = torch.long)\n",
    "            \n",
    "            \n",
    "            if gpu and torch.cuda.is_available():\n",
    "                X_batch = X_batch.cuda()\n",
    "                y_batch = y_batch.cuda()\n",
    "                torch.cuda.empty_cache()\n",
    "            #################################\n",
    "            ####### OPTIMIZATION STEP #######\n",
    "            #################################\n",
    "            optimizer.zero_grad()\n",
    "            [class_probs, pred_probs] = classifier(X_batch.view(current_batch_size, 1, -1))\n",
    "            loss = wn.WaveNetLoss(\n",
    "                audios = X_batch,\n",
    "                labels = y_batch,\n",
    "                class_probs = class_probs,\n",
    "                pred_probs = pred_probs,\n",
    "                pred_channels = 16\n",
    "                )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if batch % 10 == 0:\n",
    "                print(\"  Batch: {}/{}, Loss: {}\".format(batch+1, batches_per_epoch, loss))\n",
    "        \n",
    "            \n",
    "        # End of epoch stuff\n",
    "        seed += batch_size\n",
    "        print(\" Computing accuracy on test set...\")\n",
    "        acc = get_accuracy(valid_data, classifier.cpu(), verbose = False)\n",
    "        print(\" Accuracy: {}\".format(acc))\n",
    "    return classifier.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data = pd.concat([records_by_word_test[\"SCIENCE\"],records_by_word_test[\"TAXATION\"]])\n",
    "classifier = trainWaveNet(classifier, records_train, valid_data, \n",
    "                   num_epochs = 10, batch_size = 16, gpu = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
